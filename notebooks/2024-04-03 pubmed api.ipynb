{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Title\n",
    "[]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "sys.path.append(r\"/home/silvhua/custom_python\")\n",
    "from silvhua import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.getenv('api_ncbi') # Pubmed API key\n",
    "result_dict = dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iteration 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-03 14:30:09,078 - Pubmed_API - INFO:\n",
      "Search term: \"(\"resistance train*\"[All Fields]) AND ((y_10[Filter]) AND (meta-analysis[Filter] OR review[Filter] OR systematicreview[Filter]))\"\n",
      "\n",
      "2024-04-03 14:30:09,942 - Pubmed_API - WARNING:\n",
      "No results found.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(r\"/home/silvhua/custom_python\")\n",
    "import os\n",
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "import requests\n",
    "# from article_processing import create_text_dict_from_folder\n",
    "# from orm_summarize import *\n",
    "api_key = os.getenv('api_ncbi') # Pubmed API key\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import requests\n",
    "from Custom_Logger import *\n",
    "\n",
    "class Pubmed_API:\n",
    "    def __init__(self, api_key=os.getenv('api_ncbi'), logger=None, logging_level=logging.INFO):\n",
    "        self.api_key = api_key\n",
    "        self.logger = create_function_logger('Pubmed_API', logger, level=logging_level)\n",
    "        self.iteration = 1\n",
    "        self.responses_dict = {}\n",
    "        self.results_dict = {}\n",
    "        self.PMIDs_dict = {}\n",
    "        self.record_strings_dict = {}\n",
    "\n",
    "    def search_article(self, query, query_tag=None, publication=None, reldate=None, retmax=None,\n",
    "        systematic_only=False, review_only=False, verbose=False, additional_search_params=None\n",
    "        ):\n",
    "        base_url = f'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi'\n",
    "        if self.api_key:\n",
    "            base_url += f'&api_key={self.api_key}'\n",
    "        response = {}\n",
    "        results = pd.DataFrame()\n",
    "        search_term = f'\"{re.sub(r\"not\", \"\", query)}\"'  # Remove 'not' since it will be treated as a boolean\n",
    "        if query_tag:\n",
    "            search_term += f'{query_tag}'\n",
    "        if publication:\n",
    "            search_term = f'AND {publication} [ta]'\n",
    "        if systematic_only:\n",
    "            search_term += ' AND systematic[sb]'\n",
    "        elif review_only:\n",
    "            search_term += ' AND (systematic[sb] OR review[pt])'\n",
    "        params = {\n",
    "            'db': 'pubmed',\n",
    "            'term': search_term,\n",
    "            'retmax': 5,\n",
    "            'retmode': 'json',\n",
    "            'datetype': 'edat',\n",
    "        }\n",
    "        if reldate:\n",
    "            params['reldate'] = reldate\n",
    "        if retmax:\n",
    "            params['retmax'] = retmax\n",
    "        if additional_search_params:\n",
    "            params.update(additional_search_params)\n",
    "        self.logger.info(f'Search term: {search_term}')\n",
    "        try:\n",
    "            response = requests.get(base_url, params=params)\n",
    "            response_dict = response.json()\n",
    "            self.responses_dict[self.iteration] = response_dict\n",
    "            result_dict = self.get_article_data_by_title()\n",
    "            self.results_dict[self.iteration] = result_dict\n",
    "            self.iteration += 1\n",
    "            results = pd.DataFrame(result_dict).transpose()\n",
    "        except Exception as error:\n",
    "            error_messages = []\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            file = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = file.f_code.co_filename\n",
    "            message = f'\\tAn error occurred on line {lineno} in {filename}: {error}'\n",
    "            error_messages.append(message)\n",
    "            self.logger.error('\\n'.join(error_messages))\n",
    "        \n",
    "        return results\n",
    "\n",
    "    def get_article_data_by_title(self):\n",
    "        try:\n",
    "            result_dict = {}\n",
    "            record_strings_list = self.batch_retrieve_citation(self.responses_dict[self.iteration])\n",
    "            self.record_strings_dict[self.iteration] = record_strings_list\n",
    "            for index, record_string in enumerate(record_strings_list):\n",
    "                result_dict[index] = self.extract_pubmed_details(record_string)\n",
    "\n",
    "        except Exception as error:\n",
    "            error_messages = []\n",
    "            error_messages.append(f'Response: \\n{self.PMIDs_dict[self.iteration]}')\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            file = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = file.f_code.co_filename\n",
    "            message = f'\\tAn error occurred on line {lineno} in {filename}: {error}'\n",
    "            error_messages.append(message)\n",
    "            self.logger.error('\\n'.join(error_messages))\n",
    "        return result_dict\n",
    "\n",
    "    def batch_retrieve_citation(self, response_dict):\n",
    "        result_list = []\n",
    "        messages = []\n",
    "        try:\n",
    "            id_list = response_dict['esearchresult']['idlist']\n",
    "            self.PMIDs_dict[self.iteration] = id_list\n",
    "            if id_list:\n",
    "                self.logger.info(f'Extracting these {len(id_list)} PMIDs: {id_list}')\n",
    "                for index, id in enumerate(id_list):\n",
    "                    result_list.append(self.retrieve_citation(id).decode('utf-8'))\n",
    "                    current_index, current_id = index+1, id\n",
    "            else:\n",
    "                self.logger.warning(f'No results found.')\n",
    "        except Exception as error:\n",
    "            messages.append(f'Response: \\n{response_dict}')\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            file = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = file.f_code.co_filename\n",
    "            messages.append(f'\\tAn error occurred on line {lineno} in {filename}: {error}')\n",
    "            messages.append(f'Article {current_index} [{current_id}] not found.')\n",
    "        return result_list\n",
    "\n",
    "    def retrieve_citation(self, article_id):\n",
    "        base_url = f'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi'\n",
    "        if self.api_key:\n",
    "            base_url += f'&api_key={self.api_key}'\n",
    "        params = {\n",
    "            'db': 'pubmed',\n",
    "            'id': article_id\n",
    "        }\n",
    "\n",
    "        response = requests.get(base_url, params=params)\n",
    "        return response.content\n",
    "\n",
    "    def extract_pubmed_details(self, record_string):\n",
    "        \"\"\"\n",
    "        Helper function called by `pubmed_details_by_title` to parse article metadata from PubMed database.\n",
    "        \"\"\"\n",
    "        authors = re.findall(r'<Author ValidYN=\"Y\".*?><LastName>(.*?)</LastName><ForeName>(.*?)</ForeName>', record_string)\n",
    "        formatted_authors = ', '.join(['{} {}'.format(author[1], author[0]) for author in authors])\n",
    "\n",
    "        # Extract publication year\n",
    "        publication_year = re.search(r'<PubDate><Year>(\\d{4})</Year>', record_string)\n",
    "        publication_year = publication_year.group(1) if publication_year else ''\n",
    "        publication_month = re.search(r'<PubDate>.*?<Month>(Aug)</Month>.*?</PubDate>', record_string)\n",
    "        publication_month = publication_month.group(1) if publication_month else ''\n",
    "\n",
    "        # Extract article title\n",
    "        article_title = re.search(r'<ArticleTitle>(.*?)</ArticleTitle>', record_string)\n",
    "        article_title = article_title.group(1) if article_title else ''\n",
    "\n",
    "        # Extract journal title\n",
    "        journal_title = re.search(r'<Title>(.*?)</Title>', record_string)\n",
    "        journal_title = journal_title.group(1) if journal_title else ''\n",
    "\n",
    "        # Extract journal volume\n",
    "        journal_volume = re.search(r'<Volume>(.*?)</Volume>', record_string)\n",
    "        journal_volume = journal_volume.group(1) if journal_volume else ''\n",
    "\n",
    "        # Extract journal issue\n",
    "        journal_issue = re.search(r'<Issue>(.*?)</Issue>', record_string)\n",
    "        journal_issue = journal_issue.group(1) if journal_issue else ''\n",
    "\n",
    "        # Extract start page\n",
    "        start_page = re.search(r'<StartPage>(.*?)</StartPage>', record_string)\n",
    "        start_page = start_page.group(1) if start_page else ''\n",
    "\n",
    "        # Extract end page\n",
    "        end_page = re.search(r'<EndPage>(.*?)</EndPage>', record_string)\n",
    "        end_page = end_page.group(1) if end_page else ''\n",
    "\n",
    "        # Extract ELocationID\n",
    "        doi = re.search(r'<ELocationID.*?EIdType=\"doi\".*?>(.*?)</ELocationID>', record_string)\n",
    "        doi = doi.group(1) if doi else ''\n",
    "\n",
    "        # Extract PMID\n",
    "        pmid = re.search(r'<PMID.*?>(.*?)</PMID>', record_string)\n",
    "        pmid = pmid.group(1) if pmid else ''\n",
    "\n",
    "        abstract_matches = re.findall(r'(<AbstractText.*?>.*?</AbstractText>)', record_string)\n",
    "        self.logger.debug(f'Number of abstract sections: {len(abstract_matches)}')\n",
    "        if len(abstract_matches) > 1:\n",
    "            cleaned_abstract_sections = []\n",
    "            for match in abstract_matches:\n",
    "                clean_match = re.sub(r'<AbstractText.*?((?:Label=\".*\")?.*?>.*)</AbstractText>', r'\\1', match)\n",
    "                clean_match = re.sub(r'(?: Label=\"(.*?)\")?.*?>(.*)', r'\\1: \\2', clean_match)\n",
    "                cleaned_abstract_sections.append(clean_match)\n",
    "                \n",
    "            abstract = ''.join([f'{group}<br>' for group in cleaned_abstract_sections])\n",
    "        else:\n",
    "            abstract = re.sub(r'<AbstractText.*?>(.*?)</AbstractText>', r'\\1', abstract_matches[0])  if abstract_matches else ''\n",
    "            \n",
    "        # Extract MeshHeadingList\n",
    "        MeshHeadingList = re.search(r'<MeshHeadingList>(.*?)</MeshHeadingList>', record_string)\n",
    "        MeshHeadingList = MeshHeadingList.group(1) if MeshHeadingList else ''\n",
    "        \n",
    "        return {\n",
    "            'pubmed_title': article_title,\n",
    "            'abstract': abstract,\n",
    "            'journal': journal_title,\n",
    "            'authors': formatted_authors,\n",
    "            'year': publication_year,\n",
    "            'month': publication_month,\n",
    "            'pub_volume': journal_volume,\n",
    "            'pub_issue': journal_issue,\n",
    "            'start_page': start_page,\n",
    "            'end_page': end_page,\n",
    "            'doi': doi,\n",
    "            'pmid': pmid,\n",
    "            'mesh_headings': MeshHeadingList\n",
    "        }\n",
    "    \n",
    "iteration = 1\n",
    "query = '(\"resistance train*\"[All Fields]) AND ((y_10[Filter]) AND (meta-analysis[Filter] OR review[Filter] OR systematicreview[Filter]))'\n",
    "result_dict[iteration] = Pubmed_API()\n",
    "result_dict[iteration].search_article(query, retmax=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-03 14:34:34,405 - Pubmed_API - INFO:\n",
      "Search term: \"(\"resistance train*\"[All Fields]) AND (AND (meta-analysis[Filter] OR review[Filter] OR systematicreview[Filter]))\"\n",
      "\n",
      "2024-04-03 14:34:35,532 - Pubmed_API - WARNING:\n",
      "No results found.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iteration = 1.1\n",
    "query = '(\"resistance train*\"[All Fields]) AND (AND (meta-analysis[Filter] OR review[Filter] OR systematicreview[Filter]))'\n",
    "result_dict[iteration] = Pubmed_API()\n",
    "result_dict[iteration].search_article(query, retmax=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-03 14:35:07,969 - Pubmed_API - INFO:\n",
      "Search term: \"(\"resistance train*\")\"\n",
      "\n",
      "2024-04-03 14:35:08,540 - Pubmed_API - WARNING:\n",
      "No results found.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iteration = 1.2\n",
    "query = '(\"resistance train*\")'\n",
    "result_dict[iteration] = Pubmed_API()\n",
    "result_dict[iteration].search_article(query, retmax=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-03 14:35:35,164 - Pubmed_API - INFO:\n",
      "Search term: \"resistance train*\"\n",
      "\n",
      "2024-04-03 14:35:35,897 - Pubmed_API - INFO:\n",
      "Extracting these 2 PMIDs: ['38568258', '38565633']\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pubmed_title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>journal</th>\n",
       "      <th>authors</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>pub_volume</th>\n",
       "      <th>pub_issue</th>\n",
       "      <th>start_page</th>\n",
       "      <th>end_page</th>\n",
       "      <th>doi</th>\n",
       "      <th>pmid</th>\n",
       "      <th>mesh_headings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Is there evidence for the asymmetrical transfe...</td>\n",
       "      <td>PURPOSE: The literature predominantly addresse...</td>\n",
       "      <td>European journal of applied physiology</td>\n",
       "      <td>Vickie Wong, Jun Seob Song, Yujiro Yamada, Ryo...</td>\n",
       "      <td>2024</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>10.1007/s00421-024-05472-9</td>\n",
       "      <td>38568258</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Effect of resistance training plus enriched pr...</td>\n",
       "      <td>This study aimed to determine the effects of r...</td>\n",
       "      <td>Scientific reports</td>\n",
       "      <td>Majid Mohabbat, Hamid Arazi</td>\n",
       "      <td>2024</td>\n",
       "      <td></td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>7744</td>\n",
       "      <td></td>\n",
       "      <td>10.1038/s41598-024-58462-4</td>\n",
       "      <td>38565633</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        pubmed_title  \\\n",
       "0  Is there evidence for the asymmetrical transfe...   \n",
       "1  Effect of resistance training plus enriched pr...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  PURPOSE: The literature predominantly addresse...   \n",
       "1  This study aimed to determine the effects of r...   \n",
       "\n",
       "                                  journal  \\\n",
       "0  European journal of applied physiology   \n",
       "1                      Scientific reports   \n",
       "\n",
       "                                             authors  year month pub_volume  \\\n",
       "0  Vickie Wong, Jun Seob Song, Yujiro Yamada, Ryo...  2024                    \n",
       "1                        Majid Mohabbat, Hamid Arazi  2024               14   \n",
       "\n",
       "  pub_issue start_page end_page                         doi      pmid  \\\n",
       "0                                10.1007/s00421-024-05472-9  38568258   \n",
       "1         1       7744           10.1038/s41598-024-58462-4  38565633   \n",
       "\n",
       "  mesh_headings  \n",
       "0                \n",
       "1                "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iteration = 1.2\n",
    "query = 'resistance train*'\n",
    "result_dict[iteration] = Pubmed_API()\n",
    "result_dict[iteration].search_article(query, retmax=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-03 14:35:59,787 - Pubmed_API - INFO:\n",
      "Search term: \"\"resistance train*\"\"\n",
      "\n",
      "2024-04-03 14:36:00,439 - Pubmed_API - INFO:\n",
      "Extracting these 2 PMIDs: ['38568258', '38567973']\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pubmed_title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>journal</th>\n",
       "      <th>authors</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>pub_volume</th>\n",
       "      <th>pub_issue</th>\n",
       "      <th>start_page</th>\n",
       "      <th>end_page</th>\n",
       "      <th>doi</th>\n",
       "      <th>pmid</th>\n",
       "      <th>mesh_headings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Is there evidence for the asymmetrical transfe...</td>\n",
       "      <td>PURPOSE: The literature predominantly addresse...</td>\n",
       "      <td>European journal of applied physiology</td>\n",
       "      <td>Vickie Wong, Jun Seob Song, Yujiro Yamada, Ryo...</td>\n",
       "      <td>2024</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>10.1007/s00421-024-05472-9</td>\n",
       "      <td>38568258</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Are train horns improving road safety? Road us...</td>\n",
       "      <td>: Train horns are used as a control at railway...</td>\n",
       "      <td>Ergonomics</td>\n",
       "      <td>Gr&amp;#xe9;goire S Larue, Danielle Villoresi, Son...</td>\n",
       "      <td>2024</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>10.1080/00140139.2024.2333965</td>\n",
       "      <td>38567973</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        pubmed_title  \\\n",
       "0  Is there evidence for the asymmetrical transfe...   \n",
       "1  Are train horns improving road safety? Road us...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  PURPOSE: The literature predominantly addresse...   \n",
       "1  : Train horns are used as a control at railway...   \n",
       "\n",
       "                                  journal  \\\n",
       "0  European journal of applied physiology   \n",
       "1                              Ergonomics   \n",
       "\n",
       "                                             authors  year month pub_volume  \\\n",
       "0  Vickie Wong, Jun Seob Song, Yujiro Yamada, Ryo...  2024                    \n",
       "1  Gr&#xe9;goire S Larue, Danielle Villoresi, Son...  2024                    \n",
       "\n",
       "  pub_issue start_page end_page                            doi      pmid  \\\n",
       "0                                   10.1007/s00421-024-05472-9  38568258   \n",
       "1                    1       12  10.1080/00140139.2024.2333965  38567973   \n",
       "\n",
       "  mesh_headings  \n",
       "0                \n",
       "1                "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iteration = 1.3\n",
    "query = '\"resistance train*\"'\n",
    "result_dict[iteration] = Pubmed_API()\n",
    "result_dict[iteration].search_article(query, retmax=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-03 14:38:16,771 - Pubmed_API - INFO:\n",
      "Search term: (\"resistance train*\"[All Fields]) AND ((y_10[Filter]) AND (meta-analysis[Filter] OR review[Filter] OR systematicreview[Filter]))\n",
      "\n",
      "2024-04-03 14:38:18,104 - Pubmed_API - INFO:\n",
      "Extracting these 2 PMIDs: ['38563729', '38563037']\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pubmed_title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>journal</th>\n",
       "      <th>authors</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>pub_volume</th>\n",
       "      <th>pub_issue</th>\n",
       "      <th>start_page</th>\n",
       "      <th>end_page</th>\n",
       "      <th>doi</th>\n",
       "      <th>pmid</th>\n",
       "      <th>mesh_headings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Feasibility and Usefulness of Repetitions-In-R...</td>\n",
       "      <td>The intensity of resistance training (RT) exer...</td>\n",
       "      <td>Perceptual and motor skills</td>\n",
       "      <td>Vasco Bastos, S&amp;#xe9;rgio Machado, Diogo S Tei...</td>\n",
       "      <td>2024</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>315125241241785</td>\n",
       "      <td></td>\n",
       "      <td>10.1177/00315125241241785</td>\n",
       "      <td>38563729</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Differences in the Impact of Various Types of ...</td>\n",
       "      <td>BACKGROUND: Irisin, a myokine that is responsi...</td>\n",
       "      <td>International journal of preventive medicine</td>\n",
       "      <td>Atefe Torabi, Jalil Reisi, Mehdi Kargarfard, M...</td>\n",
       "      <td>2024</td>\n",
       "      <td></td>\n",
       "      <td>15</td>\n",
       "      <td></td>\n",
       "      <td>11</td>\n",
       "      <td></td>\n",
       "      <td>10.4103/ijpvm.ijpvm_76_23</td>\n",
       "      <td>38563037</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        pubmed_title  \\\n",
       "0  Feasibility and Usefulness of Repetitions-In-R...   \n",
       "1  Differences in the Impact of Various Types of ...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  The intensity of resistance training (RT) exer...   \n",
       "1  BACKGROUND: Irisin, a myokine that is responsi...   \n",
       "\n",
       "                                        journal  \\\n",
       "0                   Perceptual and motor skills   \n",
       "1  International journal of preventive medicine   \n",
       "\n",
       "                                             authors  year month pub_volume  \\\n",
       "0  Vasco Bastos, S&#xe9;rgio Machado, Diogo S Tei...  2024                    \n",
       "1  Atefe Torabi, Jalil Reisi, Mehdi Kargarfard, M...  2024               15   \n",
       "\n",
       "  pub_issue       start_page end_page                        doi      pmid  \\\n",
       "0            315125241241785           10.1177/00315125241241785  38563729   \n",
       "1                         11           10.4103/ijpvm.ijpvm_76_23  38563037   \n",
       "\n",
       "  mesh_headings  \n",
       "0                \n",
       "1                "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(r\"/home/silvhua/custom_python\")\n",
    "import os\n",
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "import requests\n",
    "# from article_processing import create_text_dict_from_folder\n",
    "# from orm_summarize import *\n",
    "api_key = os.getenv('api_ncbi') # Pubmed API key\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import requests\n",
    "from Custom_Logger import *\n",
    "\n",
    "class Pubmed_API:\n",
    "    def __init__(self, api_key=os.getenv('api_ncbi'), logger=None, logging_level=logging.INFO):\n",
    "        self.api_key = api_key\n",
    "        self.logger = create_function_logger('Pubmed_API', logger, level=logging_level)\n",
    "        self.iteration = 1\n",
    "        self.responses_dict = {}\n",
    "        self.results_dict = {}\n",
    "        self.PMIDs_dict = {}\n",
    "        self.record_strings_dict = {}\n",
    "\n",
    "    def search_article(self, query, query_tag=None, publication=None, reldate=None, retmax=None,\n",
    "        systematic_only=False, review_only=False, verbose=False, additional_search_params=None\n",
    "        ):\n",
    "        base_url = f'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi'\n",
    "        if self.api_key:\n",
    "            base_url += f'&api_key={self.api_key}'\n",
    "        response = {}\n",
    "        results = pd.DataFrame()\n",
    "        search_term = f'{re.sub(r\"not\", \"\", query)}'  # Remove 'not' since it will be treated as a boolean\n",
    "        if query_tag:\n",
    "            search_term += f'{query_tag}'\n",
    "        if publication:\n",
    "            search_term = f'AND {publication} [ta]'\n",
    "        if systematic_only:\n",
    "            search_term += ' AND systematic[sb]'\n",
    "        elif review_only:\n",
    "            search_term += ' AND (systematic[sb] OR review[pt])'\n",
    "        params = {\n",
    "            'db': 'pubmed',\n",
    "            'term': search_term,\n",
    "            'retmax': 5,\n",
    "            'retmode': 'json',\n",
    "            'datetype': 'edat',\n",
    "        }\n",
    "        if reldate:\n",
    "            params['reldate'] = reldate\n",
    "        if retmax:\n",
    "            params['retmax'] = retmax\n",
    "        if additional_search_params:\n",
    "            params.update(additional_search_params)\n",
    "        self.logger.info(f'Search term: {search_term}')\n",
    "        try:\n",
    "            response = requests.get(base_url, params=params)\n",
    "            response_dict = response.json()\n",
    "            self.responses_dict[self.iteration] = response_dict\n",
    "            result_dict = self.get_article_data_by_title()\n",
    "            self.results_dict[self.iteration] = result_dict\n",
    "            self.iteration += 1\n",
    "            results = pd.DataFrame(result_dict).transpose()\n",
    "        except Exception as error:\n",
    "            error_messages = []\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            file = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = file.f_code.co_filename\n",
    "            message = f'\\tAn error occurred on line {lineno} in {filename}: {error}'\n",
    "            error_messages.append(message)\n",
    "            self.logger.error('\\n'.join(error_messages))\n",
    "        \n",
    "        return results\n",
    "\n",
    "    def get_article_data_by_title(self):\n",
    "        try:\n",
    "            result_dict = {}\n",
    "            record_strings_list = self.batch_retrieve_citation(self.responses_dict[self.iteration])\n",
    "            self.record_strings_dict[self.iteration] = record_strings_list\n",
    "            for index, record_string in enumerate(record_strings_list):\n",
    "                result_dict[index] = self.extract_pubmed_details(record_string)\n",
    "\n",
    "        except Exception as error:\n",
    "            error_messages = []\n",
    "            error_messages.append(f'Response: \\n{self.PMIDs_dict[self.iteration]}')\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            file = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = file.f_code.co_filename\n",
    "            message = f'\\tAn error occurred on line {lineno} in {filename}: {error}'\n",
    "            error_messages.append(message)\n",
    "            self.logger.error('\\n'.join(error_messages))\n",
    "        return result_dict\n",
    "\n",
    "    def batch_retrieve_citation(self, response_dict):\n",
    "        result_list = []\n",
    "        messages = []\n",
    "        try:\n",
    "            id_list = response_dict['esearchresult']['idlist']\n",
    "            self.PMIDs_dict[self.iteration] = id_list\n",
    "            if id_list:\n",
    "                self.logger.info(f'Extracting these {len(id_list)} PMIDs: {id_list}')\n",
    "                for index, id in enumerate(id_list):\n",
    "                    result_list.append(self.retrieve_citation(id).decode('utf-8'))\n",
    "                    current_index, current_id = index+1, id\n",
    "            else:\n",
    "                self.logger.warning(f'No results found.')\n",
    "        except Exception as error:\n",
    "            messages.append(f'Response: \\n{response_dict}')\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            file = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = file.f_code.co_filename\n",
    "            messages.append(f'\\tAn error occurred on line {lineno} in {filename}: {error}')\n",
    "            messages.append(f'Article {current_index} [{current_id}] not found.')\n",
    "        return result_list\n",
    "\n",
    "    def retrieve_citation(self, article_id):\n",
    "        base_url = f'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi'\n",
    "        if self.api_key:\n",
    "            base_url += f'&api_key={self.api_key}'\n",
    "        params = {\n",
    "            'db': 'pubmed',\n",
    "            'id': article_id\n",
    "        }\n",
    "        response = requests.get(base_url, params=params)\n",
    "        return response.content\n",
    "\n",
    "    def extract_pubmed_details(self, record_string):\n",
    "        \"\"\"\n",
    "        Helper function called by `pubmed_details_by_title` to parse article metadata from PubMed database.\n",
    "        \"\"\"\n",
    "        authors = re.findall(r'<Author ValidYN=\"Y\".*?><LastName>(.*?)</LastName><ForeName>(.*?)</ForeName>', record_string)\n",
    "        formatted_authors = ', '.join(['{} {}'.format(author[1], author[0]) for author in authors])\n",
    "\n",
    "        # Extract publication year\n",
    "        publication_year = re.search(r'<PubDate><Year>(\\d{4})</Year>', record_string)\n",
    "        publication_year = publication_year.group(1) if publication_year else ''\n",
    "        publication_month = re.search(r'<PubDate>.*?<Month>(Aug)</Month>.*?</PubDate>', record_string)\n",
    "        publication_month = publication_month.group(1) if publication_month else ''\n",
    "\n",
    "        # Extract article title\n",
    "        article_title = re.search(r'<ArticleTitle>(.*?)</ArticleTitle>', record_string)\n",
    "        article_title = article_title.group(1) if article_title else ''\n",
    "\n",
    "        # Extract journal title\n",
    "        journal_title = re.search(r'<Title>(.*?)</Title>', record_string)\n",
    "        journal_title = journal_title.group(1) if journal_title else ''\n",
    "\n",
    "        # Extract journal volume\n",
    "        journal_volume = re.search(r'<Volume>(.*?)</Volume>', record_string)\n",
    "        journal_volume = journal_volume.group(1) if journal_volume else ''\n",
    "\n",
    "        # Extract journal issue\n",
    "        journal_issue = re.search(r'<Issue>(.*?)</Issue>', record_string)\n",
    "        journal_issue = journal_issue.group(1) if journal_issue else ''\n",
    "\n",
    "        # Extract start page\n",
    "        start_page = re.search(r'<StartPage>(.*?)</StartPage>', record_string)\n",
    "        start_page = start_page.group(1) if start_page else ''\n",
    "\n",
    "        # Extract end page\n",
    "        end_page = re.search(r'<EndPage>(.*?)</EndPage>', record_string)\n",
    "        end_page = end_page.group(1) if end_page else ''\n",
    "\n",
    "        # Extract ELocationID\n",
    "        doi = re.search(r'<ELocationID.*?EIdType=\"doi\".*?>(.*?)</ELocationID>', record_string)\n",
    "        doi = doi.group(1) if doi else ''\n",
    "\n",
    "        # Extract PMID\n",
    "        pmid = re.search(r'<PMID.*?>(.*?)</PMID>', record_string)\n",
    "        pmid = pmid.group(1) if pmid else ''\n",
    "\n",
    "        abstract_matches = re.findall(r'(<AbstractText.*?>.*?</AbstractText>)', record_string)\n",
    "        self.logger.debug(f'Number of abstract sections: {len(abstract_matches)}')\n",
    "        if len(abstract_matches) > 1:\n",
    "            cleaned_abstract_sections = []\n",
    "            for match in abstract_matches:\n",
    "                clean_match = re.sub(r'<AbstractText.*?((?:Label=\".*\")?.*?>.*)</AbstractText>', r'\\1', match)\n",
    "                clean_match = re.sub(r'(?: Label=\"(.*?)\")?.*?>(.*)', r'\\1: \\2', clean_match)\n",
    "                cleaned_abstract_sections.append(clean_match)\n",
    "                \n",
    "            abstract = ''.join([f'{group}<br>' for group in cleaned_abstract_sections])\n",
    "        else:\n",
    "            abstract = re.sub(r'<AbstractText.*?>(.*?)</AbstractText>', r'\\1', abstract_matches[0])  if abstract_matches else ''\n",
    "            \n",
    "        # Extract MeshHeadingList\n",
    "        MeshHeadingList = re.search(r'<MeshHeadingList>(.*?)</MeshHeadingList>', record_string)\n",
    "        MeshHeadingList = MeshHeadingList.group(1) if MeshHeadingList else ''\n",
    "        \n",
    "        return {\n",
    "            'pubmed_title': article_title,\n",
    "            'abstract': abstract,\n",
    "            'journal': journal_title,\n",
    "            'authors': formatted_authors,\n",
    "            'year': publication_year,\n",
    "            'month': publication_month,\n",
    "            'pub_volume': journal_volume,\n",
    "            'pub_issue': journal_issue,\n",
    "            'start_page': start_page,\n",
    "            'end_page': end_page,\n",
    "            'doi': doi,\n",
    "            'pmid': pmid,\n",
    "            'mesh_headings': MeshHeadingList\n",
    "        }\n",
    "    \n",
    "iteration = 2\n",
    "query = '(\"resistance train*\"[All Fields]) AND ((y_10[Filter]) AND (meta-analysis[Filter] OR review[Filter] OR systematicreview[Filter]))'\n",
    "result_dict[iteration] = Pubmed_API()\n",
    "result_dict[iteration].search_article(query, retmax=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iteration 2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r\"/home/silvhua/custom_python\")\n",
    "import os\n",
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "import requests\n",
    "# from article_processing import create_text_dict_from_folder\n",
    "# from orm_summarize import *\n",
    "api_key = os.getenv('api_ncbi') # Pubmed API key\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import requests\n",
    "from Custom_Logger import *\n",
    "\n",
    "class Pubmed_API:\n",
    "    def __init__(self, api_key=os.getenv('api_ncbi'), logger=None, logging_level=logging.INFO):\n",
    "        self.api_key = api_key\n",
    "        self.logger = create_function_logger('Pubmed_API', logger, level=logging_level)\n",
    "        self.iteration = 1\n",
    "        self.responses_dict = {}\n",
    "        self.results_dict = {}\n",
    "        self.PMIDs_dict = {}\n",
    "        self.record_strings_dict = {}\n",
    "\n",
    "    def search_article(self, query, query_tag=None, publication=None, reldate=None, retmax=None,\n",
    "        systematic_only=False, review_only=False, verbose=False, additional_search_params=None\n",
    "        ):\n",
    "        base_url = f'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi'\n",
    "        if self.api_key:\n",
    "            base_url += f'&api_key={self.api_key}'\n",
    "        response = {}\n",
    "        results = pd.DataFrame()\n",
    "        search_term = f'{re.sub(r\"not\", \"\", query)}'  # Remove 'not' since it will be treated as a boolean\n",
    "        if query_tag:\n",
    "            search_term += f'{query_tag}'\n",
    "        if publication:\n",
    "            search_term = f'AND {publication} [ta]'\n",
    "        if systematic_only:\n",
    "            search_term += ' AND systematic[sb]'\n",
    "        elif review_only:\n",
    "            search_term += ' AND (systematic[sb] OR review[pt])'\n",
    "        params = {\n",
    "            'db': 'pubmed',\n",
    "            'term': search_term,\n",
    "            'retmax': 5,\n",
    "            'retmode': 'json',\n",
    "            'datetype': 'edat',\n",
    "        }\n",
    "        if reldate:\n",
    "            params['reldate'] = reldate\n",
    "        if retmax:\n",
    "            params['retmax'] = retmax\n",
    "        if additional_search_params:\n",
    "            params.update(additional_search_params)\n",
    "        self.logger.info(f'Search term: {search_term}')\n",
    "        try:\n",
    "            response = requests.get(base_url, params=params)\n",
    "            response_dict = response.json()\n",
    "            self.responses_dict[self.iteration] = response_dict\n",
    "            result_dict = self.get_article_data_by_title()\n",
    "            self.results_dict[self.iteration] = result_dict\n",
    "            self.iteration += 1\n",
    "            results = pd.DataFrame(result_dict).transpose()\n",
    "        except Exception as error:\n",
    "            error_messages = []\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            file = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = file.f_code.co_filename\n",
    "            message = f'\\tAn error occurred on line {lineno} in {filename}: {error}'\n",
    "            error_messages.append(message)\n",
    "            self.logger.error('\\n'.join(error_messages))\n",
    "        \n",
    "        return results\n",
    "\n",
    "    def get_article_data_by_title(self):\n",
    "        try:\n",
    "            result_dict = {}\n",
    "            record_strings_list = self.batch_retrieve_citation(self.responses_dict[self.iteration])\n",
    "            self.record_strings_dict[self.iteration] = record_strings_list\n",
    "            for index, record_string in enumerate(record_strings_list):\n",
    "                result_dict[index] = self.extract_pubmed_details(record_string)\n",
    "\n",
    "        except Exception as error:\n",
    "            error_messages = []\n",
    "            error_messages.append(f'Response: \\n{self.PMIDs_dict[self.iteration]}')\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            file = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = file.f_code.co_filename\n",
    "            message = f'\\tAn error occurred on line {lineno} in {filename}: {error}'\n",
    "            error_messages.append(message)\n",
    "            self.logger.error('\\n'.join(error_messages))\n",
    "        return result_dict\n",
    "\n",
    "    def batch_retrieve_citation(self, response_dict):\n",
    "        result_list = []\n",
    "        messages = []\n",
    "        try:\n",
    "            id_list = response_dict['esearchresult']['idlist']\n",
    "            self.PMIDs_dict[self.iteration] = id_list\n",
    "            if id_list:\n",
    "                self.logger.info(f'Extracting these {len(id_list)} PMIDs: {id_list}')\n",
    "                for index, id in enumerate(id_list):\n",
    "                    result_list.append(self.retrieve_citation(id).decode('utf-8'))\n",
    "                    current_index, current_id = index+1, id\n",
    "            else:\n",
    "                self.logger.warning(f'No results found.')\n",
    "        except Exception as error:\n",
    "            messages.append(f'Response: \\n{response_dict}')\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            file = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = file.f_code.co_filename\n",
    "            messages.append(f'\\tAn error occurred on line {lineno} in {filename}: {error}')\n",
    "            messages.append(f'Article {current_index} [{current_id}] not found.')\n",
    "        return result_list\n",
    "\n",
    "    def retrieve_citation(self, article_id):\n",
    "        base_url = f'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi'\n",
    "        if self.api_key:\n",
    "            base_url += f'&api_key={self.api_key}'\n",
    "        params = {\n",
    "            'db': 'pubmed',\n",
    "            'id': article_id\n",
    "        }\n",
    "\n",
    "        response = requests.get(base_url, params=params)\n",
    "        return response.content\n",
    "\n",
    "    def extract_pubmed_details(self, record_string):\n",
    "        \"\"\"\n",
    "        Helper function called by `pubmed_details_by_title` to parse article metadata from PubMed database.\n",
    "        \"\"\"\n",
    "        authors = re.findall(r'<Author ValidYN=\"Y\".*?><LastName>(.*?)</LastName><ForeName>(.*?)</ForeName>', record_string)\n",
    "        formatted_authors = ', '.join(['{} {}'.format(author[1], author[0]) for author in authors])\n",
    "\n",
    "        # Extract publication year\n",
    "        publication_year = re.search(r'<PubDate><Year>(\\d{4})</Year>', record_string)\n",
    "        publication_year = publication_year.group(1) if publication_year else ''\n",
    "        publication_month = re.search(r'<PubDate>.*?<Month>(Aug)</Month>.*?</PubDate>', record_string)\n",
    "        publication_month = publication_month.group(1) if publication_month else ''\n",
    "\n",
    "        # Extract article title\n",
    "        article_title = re.search(r'<ArticleTitle>(.*?)</ArticleTitle>', record_string)\n",
    "        article_title = article_title.group(1) if article_title else ''\n",
    "\n",
    "        # Extract journal title\n",
    "        journal_title = re.search(r'<Title>(.*?)</Title>', record_string)\n",
    "        journal_title = journal_title.group(1) if journal_title else ''\n",
    "\n",
    "        # Extract journal volume\n",
    "        journal_volume = re.search(r'<Volume>(.*?)</Volume>', record_string)\n",
    "        journal_volume = journal_volume.group(1) if journal_volume else ''\n",
    "\n",
    "        # Extract journal issue\n",
    "        journal_issue = re.search(r'<Issue>(.*?)</Issue>', record_string)\n",
    "        journal_issue = journal_issue.group(1) if journal_issue else ''\n",
    "\n",
    "        # Extract start page\n",
    "        start_page = re.search(r'<StartPage>(.*?)</StartPage>', record_string)\n",
    "        start_page = start_page.group(1) if start_page else ''\n",
    "\n",
    "        # Extract end page\n",
    "        end_page = re.search(r'<EndPage>(.*?)</EndPage>', record_string)\n",
    "        end_page = end_page.group(1) if end_page else ''\n",
    "\n",
    "        # Extract ELocationID\n",
    "        doi = re.search(r'<ELocationID.*?EIdType=\"doi\".*?>(.*?)</ELocationID>', record_string)\n",
    "        doi = doi.group(1) if doi else ''\n",
    "\n",
    "        # Extract PMID\n",
    "        pmid = re.search(r'<PMID.*?>(.*?)</PMID>', record_string)\n",
    "        pmid = pmid.group(1) if pmid else ''\n",
    "\n",
    "        abstract_matches = re.findall(r'(<AbstractText.*?>.*?</AbstractText>)', record_string)\n",
    "        self.logger.debug(f'Number of abstract sections: {len(abstract_matches)}')\n",
    "        if len(abstract_matches) > 1:\n",
    "            cleaned_abstract_sections = []\n",
    "            for match in abstract_matches:\n",
    "                clean_match = re.sub(r'<AbstractText.*?((?:Label=\".*\")?.*?>.*)</AbstractText>', r'\\1', match)\n",
    "                clean_match = re.sub(r'(?: Label=\"(.*?)\")?.*?>(.*)', r'\\1: \\2', clean_match)\n",
    "                cleaned_abstract_sections.append(clean_match)\n",
    "                \n",
    "            abstract = ''.join([f'{group}<br>' for group in cleaned_abstract_sections])\n",
    "        else:\n",
    "            abstract = re.sub(r'<AbstractText.*?>(.*?)</AbstractText>', r'\\1', abstract_matches[0])  if abstract_matches else ''\n",
    "            \n",
    "        # Extract MeshHeadingList\n",
    "        MeshHeadingList = re.search(r'<MeshHeadingList>(.*?)</MeshHeadingList>', record_string)\n",
    "        MeshHeadingList = MeshHeadingList.group(1) if MeshHeadingList else ''\n",
    "        \n",
    "        return {\n",
    "            'pubmed_title': article_title,\n",
    "            'abstract': abstract,\n",
    "            'journal': journal_title,\n",
    "            'authors': formatted_authors,\n",
    "            'year': publication_year,\n",
    "            'month': publication_month,\n",
    "            'pub_volume': journal_volume,\n",
    "            'pub_issue': journal_issue,\n",
    "            'start_page': start_page,\n",
    "            'end_page': end_page,\n",
    "            'doi': doi,\n",
    "            'pmid': pmid,\n",
    "            'mesh_headings': MeshHeadingList\n",
    "        }\n",
    "    \n",
    "iteration = 2.1\n",
    "query = '(\"resistance train*\"[All Fields]) AND ((y_10[Filter]) AND (meta-analysis[Filter] OR review[Filter] OR systematicreview[Filter]))'\n",
    "result_dict[iteration] = Pubmed_API()\n",
    "result_dict[iteration].search_article(query, retmax=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next: \n",
    "* Extract mesh headings\n",
    "* Updating logging messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *End of Page*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pubmed",
   "language": "python",
   "name": "pubmed"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "11938c6bc6919ae2720b4d5011047913343b08a43b18698fd82dedb0d4417594"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
