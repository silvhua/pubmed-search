{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Title\n",
    "[]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "sys.path.append(r\"/home/silvhua/custom_python\")\n",
    "from silvhua import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the option to wrap text within cells\n",
    "pd.set_option('display.max_colwidth', 500)\n",
    "# pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_rows', 20)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.getenv('api_ncbi') # Pubmed API key\n",
    "result_dict = dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iteration 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-04 21:28:00,418 - Pubmed_API - INFO:\n",
      "Search term: 38555895 OR 38568267\n",
      "\n",
      "2024-04-04 21:28:01,364 - Pubmed_API - INFO:\n",
      "2 PMIDs found.\n",
      "['38568267', '38555895']\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['38568267', '38555895']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(r\"/home/silvhua/custom_python\")\n",
    "import os\n",
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "import requests\n",
    "# from article_processing import create_text_dict_from_folder\n",
    "# from orm_summarize import *\n",
    "api_key = os.getenv('api_ncbi') # Pubmed API key\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import requests\n",
    "from Custom_Logger import *\n",
    "\n",
    "class Pubmed_API:\n",
    "    def __init__(self, api_key=os.getenv('api_ncbi'), logger=None, logging_level=logging.INFO):\n",
    "        self.api_key = api_key\n",
    "        self.logger = create_function_logger('Pubmed_API', logger, level=logging_level)\n",
    "        self.iteration = 0\n",
    "        self.responses_dict = {}\n",
    "        self.results_dict = {}\n",
    "        self.PMIDs_dict = {}\n",
    "        self.record_strings_dict = {}\n",
    "\n",
    "    def search_article(self, query, query_tag=None, publication=None, reldate=None, retmax=None,\n",
    "        systematic_only=False, review_only=False, additional_search_params=None, ids_only=False, \n",
    "        verbose=True\n",
    "        ):\n",
    "        base_url = f'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi'\n",
    "        if self.api_key:\n",
    "            base_url += f'&api_key={self.api_key}'\n",
    "        response = {}\n",
    "        results = pd.DataFrame()\n",
    "        search_term = f'{re.sub(r\"not\", \"\", query)}'  # Remove 'not' since it will be treated as a boolean\n",
    "        if query_tag:\n",
    "            search_term += f'{query_tag}'\n",
    "        if publication:\n",
    "            search_term = f'AND {publication} [ta]'\n",
    "        if systematic_only:\n",
    "            search_term += ' AND systematic[sb]'\n",
    "        elif review_only:\n",
    "            search_term += ' AND (systematic[sb] OR review[pt])'\n",
    "        params = {\n",
    "            'db': 'pubmed',\n",
    "            'term': search_term,\n",
    "            'retmax': 5,\n",
    "            'retmode': 'json',\n",
    "            'datetype': 'edat',\n",
    "        }\n",
    "        if reldate:\n",
    "            params['reldate'] = reldate\n",
    "        if retmax:\n",
    "            params['retmax'] = retmax\n",
    "        if additional_search_params:\n",
    "            params.update(additional_search_params)\n",
    "        self.logger.info(f'Search term: {search_term}')\n",
    "        messages = []\n",
    "        try:\n",
    "            self.iteration += 1\n",
    "            response = requests.get(base_url, params=params)\n",
    "            response_dict = response.json()\n",
    "            id_list = response_dict['esearchresult']['idlist']\n",
    "            messages.append(f'{len(id_list)} PMIDs found.')\n",
    "            if verbose==True:\n",
    "                messages.append(f'{id_list}')\n",
    "            self.PMIDs_dict[self.iteration] = id_list\n",
    "            self.responses_dict[self.iteration] = response_dict\n",
    "            if ids_only==False:\n",
    "                results = self.get_article_data_by_title()\n",
    "            else:\n",
    "                results = id_list\n",
    "            self.logger.info('\\n'.join(messages))\n",
    "        except Exception as error:\n",
    "            error_messages = []\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            file = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = file.f_code.co_filename\n",
    "            message = f'\\tAn error occurred on line {lineno} in {filename}: {error}'\n",
    "            error_messages.append(message)\n",
    "            self.logger.error('\\n'.join(error_messages))\n",
    "        \n",
    "        return results\n",
    "\n",
    "    def get_article_data_by_title(self, iteration=None):\n",
    "        result_df = pd.DataFrame()\n",
    "        try:\n",
    "            result_dict = {}\n",
    "            iteration = self.iteration if iteration == None else iteration\n",
    "            record_strings_list = self.batch_retrieve_citation(iteration)\n",
    "            self.record_strings_dict[iteration] = record_strings_list\n",
    "            for index, record_string in enumerate(record_strings_list):\n",
    "                result_dict[index] = self.extract_pubmed_details(record_string)\n",
    "            self.results_dict[iteration] = result_dict\n",
    "            result_df = pd.DataFrame(result_dict).transpose()\n",
    "        except Exception as error:\n",
    "            error_messages = []\n",
    "            error_messages.append(f'Response: \\n{self.PMIDs_dict.get(iteration)}')\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            file = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = file.f_code.co_filename\n",
    "            message = f'\\tAn error occurred on line {lineno} in {filename}: {error}'\n",
    "            error_messages.append(message)\n",
    "            self.logger.error('\\n'.join(error_messages))\n",
    "        return result_df\n",
    "\n",
    "    def batch_retrieve_citation(self, iteration):\n",
    "        result_list = []\n",
    "        messages = []\n",
    "        try:\n",
    "            id_list = self.PMIDs_dict.get(iteration)\n",
    "            if id_list:\n",
    "                self.logger.info(f'Extracting these {len(id_list)} PMIDs: {id_list}')\n",
    "                for index, id in enumerate(id_list):\n",
    "                    result_list.append(self.retrieve_citation(id).decode('utf-8'))\n",
    "                    current_index, current_id = index+1, id\n",
    "            else:\n",
    "                self.logger.warning(f'No results found.')\n",
    "        except Exception as error:\n",
    "            messages.append(f'Response: \\n{self.responses_dict.get(iteration)}')\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            file = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = file.f_code.co_filename\n",
    "            messages.append(f'\\tAn error occurred on line {lineno} in {filename}: {error}')\n",
    "            messages.append(f'Article {current_index} [{current_id}] not found.')\n",
    "        return result_list\n",
    "\n",
    "    def retrieve_citation(self, article_id):\n",
    "        base_url = f'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi'\n",
    "        if self.api_key:\n",
    "            base_url += f'&api_key={self.api_key}'\n",
    "        params = {\n",
    "            'db': 'pubmed',\n",
    "            'id': article_id\n",
    "        }\n",
    "        response = requests.get(base_url, params=params)\n",
    "        return response.content\n",
    "\n",
    "    def extract_pubmed_details(self, record_string):\n",
    "        \"\"\"\n",
    "        Helper function called by `pubmed_details_by_title` to parse article metadata from PubMed database.\n",
    "        \"\"\"\n",
    "        authors = re.findall(r'<Author ValidYN=\"Y\".*?><LastName>(.*?)</LastName><ForeName>(.*?)</ForeName>', record_string)\n",
    "        formatted_authors = ', '.join(['{} {}'.format(author[1], author[0]) for author in authors])\n",
    "\n",
    "        # Extract publication year\n",
    "        publication_year = re.search(r'<PubDate><Year>(\\d{4})</Year>', record_string)\n",
    "        publication_year = publication_year.group(1) if publication_year else ''\n",
    "        publication_month = re.search(r'<PubDate>.*?<Month>(Aug)</Month>.*?</PubDate>', record_string)\n",
    "        publication_month = publication_month.group(1) if publication_month else ''\n",
    "\n",
    "        # Extract article title\n",
    "        article_title = re.search(r'<ArticleTitle>(.*?)</ArticleTitle>', record_string)\n",
    "        article_title = article_title.group(1) if article_title else ''\n",
    "\n",
    "        # Extract journal title\n",
    "        journal_title = re.search(r'<Title>(.*?)</Title>', record_string)\n",
    "        journal_title = journal_title.group(1) if journal_title else ''\n",
    "\n",
    "        # Extract journal volume\n",
    "        journal_volume = re.search(r'<Volume>(.*?)</Volume>', record_string)\n",
    "        journal_volume = journal_volume.group(1) if journal_volume else ''\n",
    "\n",
    "        # Extract journal issue\n",
    "        journal_issue = re.search(r'<Issue>(.*?)</Issue>', record_string)\n",
    "        journal_issue = journal_issue.group(1) if journal_issue else ''\n",
    "\n",
    "        # Extract start page\n",
    "        start_page = re.search(r'<StartPage>(.*?)</StartPage>', record_string)\n",
    "        start_page = start_page.group(1) if start_page else ''\n",
    "\n",
    "        # Extract end page\n",
    "        end_page = re.search(r'<EndPage>(.*?)</EndPage>', record_string)\n",
    "        end_page = end_page.group(1) if end_page else ''\n",
    "\n",
    "        # Extract ELocationID\n",
    "        doi = re.search(r'<ELocationID.*?EIdType=\"doi\".*?>(.*?)</ELocationID>', record_string)\n",
    "        doi = doi.group(1) if doi else ''\n",
    "\n",
    "        # Extract PMID\n",
    "        pmid = re.search(r'<PMID.*?>(.*?)</PMID>', record_string)\n",
    "        pmid = pmid.group(1) if pmid else ''\n",
    "\n",
    "        abstract_matches = re.findall(r'(<AbstractText.*?>.*?</AbstractText>)', record_string)\n",
    "        # self.logger.debug(f'Number of abstract sections: {len(abstract_matches)}')\n",
    "        if len(abstract_matches) > 1:\n",
    "            cleaned_abstract_sections = []\n",
    "            for match in abstract_matches:\n",
    "                clean_match = re.sub(r'<AbstractText.*?((?:Label=\".*\")?.*?>.*)</AbstractText>', r'\\1', match)\n",
    "                clean_match = re.sub(r'(?: Label=\"(.*?)\")?.*?>(.*)', r'\\1: \\2', clean_match)\n",
    "                cleaned_abstract_sections.append(clean_match)\n",
    "                \n",
    "            abstract = ''.join([f'{group}<br>' for group in cleaned_abstract_sections])\n",
    "        else:\n",
    "            abstract = re.sub(r'<AbstractText.*?>(.*?)</AbstractText>', r'\\1', abstract_matches[0])  if abstract_matches else ''\n",
    "            \n",
    "        # Extract MeshHeadingList\n",
    "        MeshHeadingList = re.search(r'<MeshHeadingList>(.*?)</MeshHeadingList>', record_string)\n",
    "        MeshHeadingList = MeshHeadingList.group(1) if MeshHeadingList else ''\n",
    "\n",
    "        # Estract MeshHeading text and any QualifierName\n",
    "        mesh_headings = []\n",
    "        pattern = r'<MeshHeading><DescriptorName.*?>(.*?)</DescriptorName>(<QualifierName.*?>.*?</QualifierName>)?</MeshHeading>'\n",
    "        matches = re.findall(pattern, MeshHeadingList)\n",
    "        for match in matches:\n",
    "            heading = match[0]\n",
    "            if match[1]: # Estract Mesh QualifierName                \n",
    "                MeshQualifiers = re.findall(\n",
    "                    r'<QualifierName.*?>(.*?)</QualifierName>', match[1]\n",
    "                    )\n",
    "                print(f'mesh qualifiers: {MeshQualifiers}')\n",
    "                for qualifier in MeshQualifiers:\n",
    "                    heading = f\"{match[0]} / {qualifier}\"\n",
    "                    mesh_headings.append(heading)\n",
    "            else:\n",
    "                mesh_headings.append(heading)\n",
    "\n",
    "        # Extract keyword\n",
    "        Keyword_List = re.search(r'<KeywordList.*?>(.*?)</KeywordList>', record_string)\n",
    "        Keyword_List = Keyword_List.group(1) if Keyword_List else ''\n",
    "        Keywords = re.findall(\n",
    "            r'<Keyword.*?>(.*?)</Keyword>', Keyword_List\n",
    "            )\n",
    "        # Extract MajorTopic text\n",
    "        MajorTopics = re.findall(\n",
    "            r'<[^>]*MajorTopicYN=\"Y\"[^>]*>([^<]+)<\\/[^>]+>', record_string\n",
    "            )\n",
    "        # Extract Publication Type\n",
    "        PublicationTypeList = re.search(r'<PublicationTypeList.*?>(.*?)</PublicationTypeList>', record_string)\n",
    "        PublicationTypeList = PublicationTypeList.group(1) if PublicationTypeList else ''\n",
    "        PublicationType = re.findall(\n",
    "            r'<PublicationType.*?>(.*?)</PublicationType>', PublicationTypeList\n",
    "            )\n",
    "        return {\n",
    "            'pubmed_title': article_title,\n",
    "            'abstract': abstract,\n",
    "            'journal': journal_title,\n",
    "            'authors': formatted_authors,\n",
    "            'year': publication_year,\n",
    "            'month': publication_month,\n",
    "            'pub_volume': journal_volume,\n",
    "            'pub_issue': journal_issue,\n",
    "            'start_page': start_page,\n",
    "            'end_page': end_page,\n",
    "            'doi': doi,\n",
    "            'pmid': pmid,\n",
    "            'mesh_headings': mesh_headings,\n",
    "            'keywords': Keywords,\n",
    "            'major_topics': MajorTopics,\n",
    "            'publication_type': PublicationType\n",
    "        }\n",
    "    \n",
    "iteration = 4\n",
    "# query = '(\"resistance train*\"[All Fields]) AND ((y_10[Filter]) AND (meta-analysis[Filter] OR review[Filter] OR systematicreview[Filter]))'\n",
    "# query = 'Factors associated with different types of hip fractures among elderly patients a tertiary hospital in Pahang: A retrospective cross-sectional study'\n",
    "query = '38555895 OR 38568267'\n",
    "result_dict[iteration] = Pubmed_API()\n",
    "ids_list = result_dict[iteration].search_article(query, retmax=5, ids_only=True)\n",
    "ids_list\n",
    "# df = result_dict[iteration].get_article_data_by_title()\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-04 21:28:22,749 - Pubmed_API - INFO:\n",
      "Extracting these 2 PMIDs: ['38568267', '38555895']\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mesh qualifiers: ['epidemiology', 'complications']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pubmed_title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>journal</th>\n",
       "      <th>authors</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>pub_volume</th>\n",
       "      <th>pub_issue</th>\n",
       "      <th>start_page</th>\n",
       "      <th>end_page</th>\n",
       "      <th>doi</th>\n",
       "      <th>pmid</th>\n",
       "      <th>mesh_headings</th>\n",
       "      <th>keywords</th>\n",
       "      <th>major_topics</th>\n",
       "      <th>publication_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Inspiratory Training for Improving Respiratory...</td>\n",
       "      <td>PURPOSE: To investigate the effects of inspira...</td>\n",
       "      <td>Pediatric physical therapy : the official publ...</td>\n",
       "      <td>K&amp;#xea;nia K P Menezes, Patrick R Avelino, Mar...</td>\n",
       "      <td>2024</td>\n",
       "      <td></td>\n",
       "      <td>36</td>\n",
       "      <td>2</td>\n",
       "      <td>207</td>\n",
       "      <td>215</td>\n",
       "      <td>10.1097/PEP.0000000000001092</td>\n",
       "      <td>38568267</td>\n",
       "      <td>[Child, Humans, Cerebral Palsy, Walking, Muscl...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Cerebral Palsy, Resistance Training]</td>\n",
       "      <td>[Systematic Review, Meta-Analysis, Journal Art...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Factors associated with different types of hip...</td>\n",
       "      <td>INTRODUCTION: Hip fractures, predominantly due...</td>\n",
       "      <td>The Medical journal of Malaysia</td>\n",
       "      <td>R Mohd Yusoff, Z A Mulud, M Mohammadnezhad</td>\n",
       "      <td>2024</td>\n",
       "      <td></td>\n",
       "      <td>79</td>\n",
       "      <td>Suppl 1</td>\n",
       "      <td>117</td>\n",
       "      <td>121</td>\n",
       "      <td></td>\n",
       "      <td>38555895</td>\n",
       "      <td>[Aged, Humans, Female, Retrospective Studies, ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Hip Fractures]</td>\n",
       "      <td>[Journal Article]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        pubmed_title  \\\n",
       "0  Inspiratory Training for Improving Respiratory...   \n",
       "1  Factors associated with different types of hip...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  PURPOSE: To investigate the effects of inspira...   \n",
       "1  INTRODUCTION: Hip fractures, predominantly due...   \n",
       "\n",
       "                                             journal  \\\n",
       "0  Pediatric physical therapy : the official publ...   \n",
       "1                    The Medical journal of Malaysia   \n",
       "\n",
       "                                             authors  year month pub_volume  \\\n",
       "0  K&#xea;nia K P Menezes, Patrick R Avelino, Mar...  2024               36   \n",
       "1         R Mohd Yusoff, Z A Mulud, M Mohammadnezhad  2024               79   \n",
       "\n",
       "  pub_issue start_page end_page                           doi      pmid  \\\n",
       "0         2        207      215  10.1097/PEP.0000000000001092  38568267   \n",
       "1   Suppl 1        117      121                                38555895   \n",
       "\n",
       "                                       mesh_headings keywords  \\\n",
       "0  [Child, Humans, Cerebral Palsy, Walking, Muscl...       []   \n",
       "1  [Aged, Humans, Female, Retrospective Studies, ...       []   \n",
       "\n",
       "                            major_topics  \\\n",
       "0  [Cerebral Palsy, Resistance Training]   \n",
       "1                        [Hip Fractures]   \n",
       "\n",
       "                                    publication_type  \n",
       "0  [Systematic Review, Meta-Analysis, Journal Art...  \n",
       "1                                  [Journal Article]  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = result_dict[iteration].get_article_data_by_title()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-04 22:13:57,402 - extract_pubmed_details_df - DEBUG:\n",
      "Found existing handlers: [<StreamHandler stderr (DEBUG)>]. Found existing console handler: <StreamHandler stderr (DEBUG)>. Setting console handler level to: 10. \n",
      "\n",
      "2024-04-04 22:13:57,405 - extract_pubmed_details_df - INFO:\n",
      "***Running `df_extractall` with regex <AbstractText.*?(?: Label=\"(.*?)\")?.*?>(.*?)</AbstractText>***\n",
      "\tparent_regex: <Abstract>(.*?)</Abstract>\n",
      "\n",
      "2024-04-04 22:13:57,415 - extract_pubmed_details_df - DEBUG:\n",
      "Number of capture groups: 2\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_title</th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Inspiratory Training for Improving Respiratory Strength, Pulmonary Function, and Walking in Cerebral Palsy: A Meta-Analysis.</td>\n",
       "      <td>PURPOSE: To investigate the effects of inspiratory strength training on respiratory muscle strength, pulmonary function, and walking capacity in children with cerebral palsy, with Gross Motor Function Classification System I to III. METHODS: Searches were conducted in CINAHL, LILACS, MEDLINE, and Physiotherapy Evidence Database (PEDro) databases. The outcomes of interest were respiratory muscle strength, pulmonary function, and walking capacity. The quality was assessed by PEDro Scale. The G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Factors associated with different types of hip fractures among elderly patients a tertiary hospital in Pahang: A retrospective cross-sectional study.</td>\n",
       "      <td>INTRODUCTION: Hip fractures, predominantly due to decreased bone density and falls, significantly impact elderly health, disproportionately affecting women and placing a strain on healthcare resources. This study aims to conduct an indepth epidemiological analysis of hip fracture incidence among the elderly in Pahang, Malaysia, to inform better healthcare strategies. MATERIALS AND METHODS: In this retrospective study, medical records of patients admitted with hip fractures between 2019 and 2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                           article_title  \\\n",
       "0                           Inspiratory Training for Improving Respiratory Strength, Pulmonary Function, and Walking in Cerebral Palsy: A Meta-Analysis.   \n",
       "1  Factors associated with different types of hip fractures among elderly patients a tertiary hospital in Pahang: A retrospective cross-sectional study.   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              abstract  \n",
       "0  PURPOSE: To investigate the effects of inspiratory strength training on respiratory muscle strength, pulmonary function, and walking capacity in children with cerebral palsy, with Gross Motor Function Classification System I to III. METHODS: Searches were conducted in CINAHL, LILACS, MEDLINE, and Physiotherapy Evidence Database (PEDro) databases. The outcomes of interest were respiratory muscle strength, pulmonary function, and walking capacity. The quality was assessed by PEDro Scale. The G...  \n",
       "1  INTRODUCTION: Hip fractures, predominantly due to decreased bone density and falls, significantly impact elderly health, disproportionately affecting women and placing a strain on healthcare resources. This study aims to conduct an indepth epidemiological analysis of hip fracture incidence among the elderly in Pahang, Malaysia, to inform better healthcare strategies. MATERIALS AND METHODS: In this retrospective study, medical records of patients admitted with hip fractures between 2019 and 2...  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from table_mapping import concat_columns\n",
    "def df_extractall(\n",
    "        series, regex, parent_regex=None, nested_regex=None, sep=[' ', ' / '], \n",
    "        join_strings=False, logger=None\n",
    "        ):\n",
    "    logger = create_function_logger('df_extractall', logger)\n",
    "    messages = []\n",
    "    messages.append(f'***Running `df_extractall` with regex {regex}***')\n",
    "    if parent_regex:\n",
    "        messages.append(f'\\tparent_regex: {parent_regex}')\n",
    "    if nested_regex:\n",
    "        messages.append(f'\\tnested_regex: {nested_regex}')\n",
    "    logger.info('\\n'.join(messages))\n",
    "    if parent_regex:\n",
    "        extracted = series.str.extract(parent_regex, expand=False)\n",
    "        series = extracted\n",
    "    extracted = series.str.extractall(regex).replace({np.nan: ''})\n",
    "    if extracted.shape[1] >= 1:\n",
    "        joined_values = extracted[0]\n",
    "    else:\n",
    "        messages.warning('No matches found.')\n",
    "        return series\n",
    "    debug_messages = []\n",
    "    debug_messages.append(f'Number of capture groups: {extracted.shape[1]}')\n",
    "    if extracted.shape[1] > 1:\n",
    "        extracted.index.names = [f'{name if name else \"index\"}{index if index !=0 else \"\"}' for index, name in enumerate(extracted.index.names)]\n",
    "        for i in range(1, extracted.shape[1]):\n",
    "            if nested_regex:\n",
    "                matches = extracted[i].str.extractall(nested_regex)#.replace({np.nan: ''})\n",
    "                debug_messages.append(f'Number of nested capture groups: {matches.shape[1]}')\n",
    "                matches.columns = [f'nested_text{column}' for column in matches.columns]\n",
    "                regex_df = extracted.merge(\n",
    "                    matches, how='left', left_index=True, right_index=True\n",
    "                ).replace({np.nan: ''})\n",
    "                nested_separator = sep if type(sep) == str else sep[1]\n",
    "                if i == 1:\n",
    "                    root_column = 0 \n",
    "                    capture_group_separator = nested_separator\n",
    "                else:\n",
    "                    root_column = 'Text'\n",
    "                    capture_group_separator = sep if type(sep) == str else sep[-1]\n",
    "                regex_df = concat_columns(\n",
    "                    regex_df, [root_column, 'nested_text0'], 'Text', \n",
    "                    sep=capture_group_separator\n",
    "                )\n",
    "                joined_values = regex_df['Text']\n",
    "\n",
    "            else:\n",
    "                separator = sep if type(sep) == str else sep[0]\n",
    "                joined_values = joined_values + separator + extracted[i]\n",
    "    new_series = joined_values.groupby(level=0).apply(lambda groupby: [match for match in groupby])\n",
    "    if (type(join_strings) == str) | (join_strings == True):\n",
    "        new_series = new_series.apply(lambda x: f'{join_strings if type(join_strings) == str else \" \"}'.join(x))\n",
    "    logger.debug('\\n'.join(debug_messages))\n",
    "    return new_series\n",
    "\n",
    "def extract_pubmed_details_df(record_strings_list, logger=None, logging_level=10):\n",
    "    df = pd.DataFrame()\n",
    "    logger = create_function_logger('extract_pubmed_details_df', logger, level=logging_level)\n",
    "    record_strings = pd.Series(record_strings_list)\n",
    "\n",
    "    regex_dict = {\n",
    "        'article_title': r'<ArticleTitle>(.*?)</ArticleTitle>',\n",
    "        # 'pmid': r'<PMID.*?>(.*?)</PMID>',\n",
    "        # 'journal': r'<Title>(.*?)</Title>',\n",
    "        # 'volume': r'<Volume>(.*?)</Volume>',\n",
    "        # 'issue': r'<Issue>(.*?)</Issue>',\n",
    "        # 'year': r'<PubDate><Year>(\\d{4})</Year>',\n",
    "        # 'month': r'<PubDate>.*?<Month>(Aug)</Month>.*?</PubDate>',\n",
    "        # 'start_page': r'<StartPage>(.*?)</StartPage>',\n",
    "        # 'end_page': r'<EndPage>(.*?)</EndPage>',\n",
    "        # 'doi': r'<ELocationID.*?EIdType=\"doi\".*?>(.*?)</ELocationID>',\n",
    "\n",
    "    }\n",
    "    for column, regex in regex_dict.items():\n",
    "        df[column] = record_strings.str.extract(regex)\n",
    "    # df['mesh_headings'] = df_extractall(\n",
    "    #     record_strings, \n",
    "    #     parent_regex=r'<MeshHeadingList>(.*?)</MeshHeadingList>',\n",
    "    #     regex=r'<MeshHeading><DescriptorName.*?>(.*?)</DescriptorName>(<QualifierName.*?>.*?</QualifierName>)?</MeshHeading>',\n",
    "    #     nested_regex=r'<QualifierName.*?>(.*?)</QualifierName>', logger=logger\n",
    "    # )\n",
    "\n",
    "    # df['authors'] = df_extractall(\n",
    "    #     record_strings, sep=' ',\n",
    "    #     regex=r'<Author ValidYN=\"Y\".*?><LastName>(.*?)</LastName><ForeName>(.*?)</ForeName>',\n",
    "    #     logger=logger \n",
    "    # )\n",
    "    # df['abstract'] = df_extractall(\n",
    "    #     record_strings,\n",
    "    #     regex = r'(<AbstractText.*?>.*?</AbstractText>)',\n",
    "    #     nested_regex=r'(?: Label=\"(.*?)\")?.*?>(.*)', logger=logger, sep=['\\n', ' ']\n",
    "    # )\n",
    "    df['abstract'] = df_extractall(\n",
    "        record_strings, parent_regex=r'<Abstract>(.*?)</Abstract>',\n",
    "        regex = r'<AbstractText.*?(?: Label=\"(.*?)\")?.*?>(.*?)</AbstractText>',\n",
    "        # nested_regex=r'(?: Label=\"(.*?)\")?.*?>(.*)', \n",
    "        logger=logger, sep=': ', join_strings=' '\n",
    "    )\n",
    "    \n",
    "    return df\n",
    "\n",
    "record_strings_list = result_dict[iteration].record_strings_dict[1]\n",
    "df = extract_pubmed_details_df(record_strings_list)\n",
    "# df.loc[1]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# iteration 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-04 08:56:20,361 - Pubmed_API - INFO:\n",
      "Search term: 38555895 OR 38568267\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-04 08:56:21,906 - Pubmed_API - INFO:\n",
      "2 PMIDs found.\n",
      "['38568267', '38555895']\n",
      "\n",
      "2024-04-04 08:56:21,933 - Pubmed_API - INFO:\n",
      "Extracting these 2 PMIDs: ['38568267', '38555895']\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mesh qualifiers: ['epidemiology', 'complications']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pubmed_title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>journal</th>\n",
       "      <th>authors</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>pub_volume</th>\n",
       "      <th>pub_issue</th>\n",
       "      <th>start_page</th>\n",
       "      <th>end_page</th>\n",
       "      <th>doi</th>\n",
       "      <th>pmid</th>\n",
       "      <th>mesh_headings</th>\n",
       "      <th>keywords</th>\n",
       "      <th>major_topics</th>\n",
       "      <th>publication_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Inspiratory Training for Improving Respiratory...</td>\n",
       "      <td>PURPOSE: To investigate the effects of inspira...</td>\n",
       "      <td>Pediatric physical therapy : the official publ...</td>\n",
       "      <td>K&amp;#xea;nia K P Menezes, Patrick R Avelino, Mar...</td>\n",
       "      <td>2024</td>\n",
       "      <td></td>\n",
       "      <td>36</td>\n",
       "      <td>2</td>\n",
       "      <td>207</td>\n",
       "      <td>215</td>\n",
       "      <td>10.1097/PEP.0000000000001092</td>\n",
       "      <td>38568267</td>\n",
       "      <td>[Child, Humans, Cerebral Palsy, Walking, Muscl...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Cerebral Palsy, Resistance Training]</td>\n",
       "      <td>[Systematic Review, Meta-Analysis, Journal Art...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Factors associated with different types of hip...</td>\n",
       "      <td>INTRODUCTION: Hip fractures, predominantly due...</td>\n",
       "      <td>The Medical journal of Malaysia</td>\n",
       "      <td>R Mohd Yusoff, Z A Mulud, M Mohammadnezhad</td>\n",
       "      <td>2024</td>\n",
       "      <td></td>\n",
       "      <td>79</td>\n",
       "      <td>Suppl 1</td>\n",
       "      <td>117</td>\n",
       "      <td>121</td>\n",
       "      <td></td>\n",
       "      <td>38555895</td>\n",
       "      <td>[Aged, Humans, Female, Retrospective Studies, ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Hip Fractures]</td>\n",
       "      <td>[Journal Article]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        pubmed_title  \\\n",
       "0  Inspiratory Training for Improving Respiratory...   \n",
       "1  Factors associated with different types of hip...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  PURPOSE: To investigate the effects of inspira...   \n",
       "1  INTRODUCTION: Hip fractures, predominantly due...   \n",
       "\n",
       "                                             journal  \\\n",
       "0  Pediatric physical therapy : the official publ...   \n",
       "1                    The Medical journal of Malaysia   \n",
       "\n",
       "                                             authors  year month pub_volume  \\\n",
       "0  K&#xea;nia K P Menezes, Patrick R Avelino, Mar...  2024               36   \n",
       "1         R Mohd Yusoff, Z A Mulud, M Mohammadnezhad  2024               79   \n",
       "\n",
       "  pub_issue start_page end_page                           doi      pmid  \\\n",
       "0         2        207      215  10.1097/PEP.0000000000001092  38568267   \n",
       "1   Suppl 1        117      121                                38555895   \n",
       "\n",
       "                                       mesh_headings keywords  \\\n",
       "0  [Child, Humans, Cerebral Palsy, Walking, Muscl...       []   \n",
       "1  [Aged, Humans, Female, Retrospective Studies, ...       []   \n",
       "\n",
       "                            major_topics  \\\n",
       "0  [Cerebral Palsy, Resistance Training]   \n",
       "1                        [Hip Fractures]   \n",
       "\n",
       "                                    publication_type  \n",
       "0  [Systematic Review, Meta-Analysis, Journal Art...  \n",
       "1                                  [Journal Article]  "
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(r\"/home/silvhua/custom_python\")\n",
    "import os\n",
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "import requests\n",
    "# from article_processing import create_text_dict_from_folder\n",
    "# from orm_summarize import *\n",
    "api_key = os.getenv('api_ncbi') # Pubmed API key\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import requests\n",
    "from Custom_Logger import *\n",
    "\n",
    "class Pubmed_API:\n",
    "    def __init__(self, api_key=os.getenv('api_ncbi'), logger=None, logging_level=logging.INFO):\n",
    "        self.api_key = api_key\n",
    "        self.logger = create_function_logger('Pubmed_API', logger, level=logging_level)\n",
    "        self.iteration = 0\n",
    "        self.responses_dict = {}\n",
    "        self.results_dict = {}\n",
    "        self.PMIDs_dict = {}\n",
    "        self.record_strings_dict = {}\n",
    "\n",
    "    def search_article(self, query, query_tag=None, publication=None, reldate=None, retmax=None,\n",
    "        systematic_only=False, review_only=False, additional_search_params=None, ids_only=False, \n",
    "        verbose=True\n",
    "        ):\n",
    "        base_url = f'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi'\n",
    "        if self.api_key:\n",
    "            base_url += f'&api_key={self.api_key}'\n",
    "        response = {}\n",
    "        results = pd.DataFrame()\n",
    "        search_term = f'{re.sub(r\"not\", \"\", query)}'  # Remove 'not' since it will be treated as a boolean\n",
    "        if query_tag:\n",
    "            search_term += f'{query_tag}'\n",
    "        if publication:\n",
    "            search_term = f'AND {publication} [ta]'\n",
    "        if systematic_only:\n",
    "            search_term += ' AND systematic[sb]'\n",
    "        elif review_only:\n",
    "            search_term += ' AND (systematic[sb] OR review[pt])'\n",
    "        params = {\n",
    "            'db': 'pubmed',\n",
    "            'term': search_term,\n",
    "            'retmax': 5,\n",
    "            'retmode': 'json',\n",
    "            'datetype': 'edat',\n",
    "        }\n",
    "        if reldate:\n",
    "            params['reldate'] = reldate\n",
    "        if retmax:\n",
    "            params['retmax'] = retmax\n",
    "        if additional_search_params:\n",
    "            params.update(additional_search_params)\n",
    "        self.logger.info(f'Search term: {search_term}')\n",
    "        messages = []\n",
    "        try:\n",
    "            self.iteration += 1\n",
    "            response = requests.get(base_url, params=params)\n",
    "            response_dict = response.json()\n",
    "            id_list = response_dict['esearchresult']['idlist']\n",
    "            messages.append(f'{len(id_list)} PMIDs found.')\n",
    "            if verbose==True:\n",
    "                messages.append(f'{id_list}')\n",
    "            self.PMIDs_dict[self.iteration] = id_list\n",
    "            self.responses_dict[self.iteration] = response_dict\n",
    "            if ids_only==False:\n",
    "                results = self.get_article_data_by_title()\n",
    "            else:\n",
    "                results = id_list\n",
    "            self.logger.info('\\n'.join(messages))\n",
    "        except Exception as error:\n",
    "            error_messages = []\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            file = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = file.f_code.co_filename\n",
    "            message = f'\\tAn error occurred on line {lineno} in {filename}: {error}'\n",
    "            error_messages.append(message)\n",
    "            self.logger.error('\\n'.join(error_messages))\n",
    "        \n",
    "        return results\n",
    "\n",
    "    def get_article_data_by_title(self, iteration=None):\n",
    "        result_df = pd.DataFrame()\n",
    "        try:\n",
    "            result_dict = {}\n",
    "            iteration = self.iteration if iteration == None else iteration\n",
    "            record_strings_list = self.batch_retrieve_citation(iteration)\n",
    "            self.record_strings_dict[iteration] = record_strings_list\n",
    "            for index, record_string in enumerate(record_strings_list):\n",
    "                result_dict[index] = self.extract_pubmed_details(record_string)\n",
    "            self.results_dict[iteration] = result_dict\n",
    "            result_df = pd.DataFrame(result_dict).transpose()\n",
    "        except Exception as error:\n",
    "            error_messages = []\n",
    "            error_messages.append(f'Response: \\n{self.PMIDs_dict.get(iteration)}')\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            file = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = file.f_code.co_filename\n",
    "            message = f'\\tAn error occurred on line {lineno} in {filename}: {error}'\n",
    "            error_messages.append(message)\n",
    "            self.logger.error('\\n'.join(error_messages))\n",
    "        return result_df\n",
    "\n",
    "    def batch_retrieve_citation(self, iteration):\n",
    "        result_list = []\n",
    "        messages = []\n",
    "        try:\n",
    "            id_list = self.PMIDs_dict.get(iteration)\n",
    "            if id_list:\n",
    "                self.logger.info(f'Extracting these {len(id_list)} PMIDs: {id_list}')\n",
    "                for index, id in enumerate(id_list):\n",
    "                    result_list.append(self.retrieve_citation(id).decode('utf-8'))\n",
    "                    current_index, current_id = index+1, id\n",
    "            else:\n",
    "                self.logger.warning(f'No results found.')\n",
    "        except Exception as error:\n",
    "            messages.append(f'Response: \\n{self.responses_dict.get(iteration)}')\n",
    "            exc_type, exc_obj, tb = sys.exc_info()\n",
    "            file = tb.tb_frame\n",
    "            lineno = tb.tb_lineno\n",
    "            filename = file.f_code.co_filename\n",
    "            messages.append(f'\\tAn error occurred on line {lineno} in {filename}: {error}')\n",
    "            messages.append(f'Article {current_index} [{current_id}] not found.')\n",
    "        return result_list\n",
    "\n",
    "    def retrieve_citation(self, article_id):\n",
    "        base_url = f'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi'\n",
    "        if self.api_key:\n",
    "            base_url += f'&api_key={self.api_key}'\n",
    "        params = {\n",
    "            'db': 'pubmed',\n",
    "            'id': article_id\n",
    "        }\n",
    "        response = requests.get(base_url, params=params)\n",
    "        return response.content\n",
    "\n",
    "    def extract_pubmed_details(self, record_string):\n",
    "        \"\"\"\n",
    "        Helper function called by `pubmed_details_by_title` to parse article metadata from PubMed database.\n",
    "        \"\"\"\n",
    "        authors = re.findall(r'<Author ValidYN=\"Y\".*?><LastName>(.*?)</LastName><ForeName>(.*?)</ForeName>', record_string)\n",
    "        formatted_authors = ', '.join(['{} {}'.format(author[1], author[0]) for author in authors])\n",
    "\n",
    "        # Extract publication year\n",
    "        publication_year = re.search(r'<PubDate><Year>(\\d{4})</Year>', record_string)\n",
    "        publication_year = publication_year.group(1) if publication_year else ''\n",
    "        publication_month = re.search(r'<PubDate>.*?<Month>(Aug)</Month>.*?</PubDate>', record_string)\n",
    "        publication_month = publication_month.group(1) if publication_month else ''\n",
    "\n",
    "        # Extract article title\n",
    "        article_title = re.search(r'<ArticleTitle>(.*?)</ArticleTitle>', record_string)\n",
    "        article_title = article_title.group(1) if article_title else ''\n",
    "\n",
    "        # Extract journal title\n",
    "        journal_title = re.search(r'<Title>(.*?)</Title>', record_string)\n",
    "        journal_title = journal_title.group(1) if journal_title else ''\n",
    "\n",
    "        # Extract journal volume\n",
    "        journal_volume = re.search(r'<Volume>(.*?)</Volume>', record_string)\n",
    "        journal_volume = journal_volume.group(1) if journal_volume else ''\n",
    "\n",
    "        # Extract journal issue\n",
    "        journal_issue = re.search(r'<Issue>(.*?)</Issue>', record_string)\n",
    "        journal_issue = journal_issue.group(1) if journal_issue else ''\n",
    "\n",
    "        # Extract start page\n",
    "        start_page = re.search(r'<StartPage>(.*?)</StartPage>', record_string)\n",
    "        start_page = start_page.group(1) if start_page else ''\n",
    "\n",
    "        # Extract end page\n",
    "        end_page = re.search(r'<EndPage>(.*?)</EndPage>', record_string)\n",
    "        end_page = end_page.group(1) if end_page else ''\n",
    "\n",
    "        # Extract ELocationID\n",
    "        doi = re.search(r'<ELocationID.*?EIdType=\"doi\".*?>(.*?)</ELocationID>', record_string)\n",
    "        doi = doi.group(1) if doi else ''\n",
    "\n",
    "        # Extract PMID\n",
    "        pmid = re.search(r'<PMID.*?>(.*?)</PMID>', record_string)\n",
    "        pmid = pmid.group(1) if pmid else ''\n",
    "\n",
    "        abstract_matches = re.findall(r'(<AbstractText.*?>.*?</AbstractText>)', record_string)\n",
    "        # self.logger.debug(f'Number of abstract sections: {len(abstract_matches)}')\n",
    "        if len(abstract_matches) > 1:\n",
    "            cleaned_abstract_sections = []\n",
    "            for match in abstract_matches:\n",
    "                clean_match = re.sub(r'<AbstractText.*?((?:Label=\".*\")?.*?>.*)</AbstractText>', r'\\1', match)\n",
    "                clean_match = re.sub(r'(?: Label=\"(.*?)\")?.*?>(.*)', r'\\1: \\2', clean_match)\n",
    "                cleaned_abstract_sections.append(clean_match)\n",
    "                \n",
    "            abstract = ''.join([f'{group}<br>' for group in cleaned_abstract_sections])\n",
    "        else:\n",
    "            abstract = re.sub(r'<AbstractText.*?>(.*?)</AbstractText>', r'\\1', abstract_matches[0])  if abstract_matches else ''\n",
    "            \n",
    "        # Extract MeshHeadingList\n",
    "        MeshHeadingList = re.search(r'<MeshHeadingList>(.*?)</MeshHeadingList>', record_string)\n",
    "        MeshHeadingList = MeshHeadingList.group(1) if MeshHeadingList else ''\n",
    "\n",
    "        # Estract MeshHeading text and any QualifierName\n",
    "        mesh_headings = []\n",
    "        pattern = r'<MeshHeading><DescriptorName.*?>(.*?)</DescriptorName>(<QualifierName.*?>.*?</QualifierName>)?</MeshHeading>'\n",
    "        matches = re.findall(pattern, MeshHeadingList)\n",
    "        for match in matches:\n",
    "            heading = match[0]\n",
    "            if match[1]: # Estract Mesh QualifierName                \n",
    "                MeshQualifiers = re.findall(\n",
    "                    r'<QualifierName.*?>(.*?)</QualifierName>', match[1]\n",
    "                    )\n",
    "                print(f'mesh qualifiers: {MeshQualifiers}')\n",
    "                for qualifier in MeshQualifiers:\n",
    "                    heading = f\"{match[0]} / {qualifier}\"\n",
    "                    mesh_headings.append(heading)\n",
    "            else:\n",
    "                mesh_headings.append(heading)\n",
    "\n",
    "        # Extract keyword\n",
    "        Keyword_List = re.search(r'<KeywordList.*?>(.*?)</KeywordList>', record_string)\n",
    "        Keyword_List = Keyword_List.group(1) if Keyword_List else ''\n",
    "        Keywords = re.findall(\n",
    "            r'<Keyword.*?>(.*?)</Keyword>', Keyword_List\n",
    "            )\n",
    "        # Extract MajorTopic text\n",
    "        MajorTopics = re.findall(\n",
    "            r'<[^>]*MajorTopicYN=\"Y\"[^>]*>([^<]+)<\\/[^>]+>', record_string\n",
    "            )\n",
    "        # Extract Publication Type\n",
    "        PublicationTypeList = re.search(r'<PublicationTypeList.*?>(.*?)</PublicationTypeList>', record_string)\n",
    "        PublicationTypeList = PublicationTypeList.group(1) if PublicationTypeList else ''\n",
    "        PublicationType = re.findall(\n",
    "            r'<PublicationType.*?>(.*?)</PublicationType>', PublicationTypeList\n",
    "            )\n",
    "        return {\n",
    "            'pubmed_title': article_title,\n",
    "            'abstract': abstract,\n",
    "            'journal': journal_title,\n",
    "            'authors': formatted_authors,\n",
    "            'year': publication_year,\n",
    "            'month': publication_month,\n",
    "            'pub_volume': journal_volume,\n",
    "            'pub_issue': journal_issue,\n",
    "            'start_page': start_page,\n",
    "            'end_page': end_page,\n",
    "            'doi': doi,\n",
    "            'pmid': pmid,\n",
    "            'mesh_headings': mesh_headings,\n",
    "            'keywords': Keywords,\n",
    "            'major_topics': MajorTopics,\n",
    "            'publication_type': PublicationType\n",
    "        }\n",
    "    \n",
    "iteration = 4\n",
    "# query = '(\"resistance train*\"[All Fields]) AND ((y_10[Filter]) AND (meta-analysis[Filter] OR review[Filter] OR systematicreview[Filter]))'\n",
    "# query = 'Factors associated with different types of hip fractures among elderly patients a tertiary hospital in Pahang: A retrospective cross-sectional study'\n",
    "query = '38555895 OR 38568267'\n",
    "result_dict[iteration] = Pubmed_API()\n",
    "ids_list = result_dict[iteration].search_article(query, retmax=5, ids_only=True)\n",
    "df = result_dict[iteration].get_article_data_by_title()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *End of Page*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pubmed",
   "language": "python",
   "name": "pubmed"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "11938c6bc6919ae2720b4d5011047913343b08a43b18698fd82dedb0d4417594"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
